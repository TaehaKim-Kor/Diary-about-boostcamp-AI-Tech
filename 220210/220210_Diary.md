<details>
<summary>Writing Specification</summary>
<div markdown="1">

>Date : 22.02.10
>
>강좌 분류 : DL Basic
>
>>강좌 번호 : 9
>>
>>제목 : Generative model 1
>
>>강좌 번호 : 10 
>>
>>제목 : Generative model 2

</div>
</details>

<details>
<summary>오늘 들은 강의 총평</summary>
<div markdown="1">

Generative Model, 나도 모르는 다양한 것들이 있었다.

뭐... 생성 모델이라고 한다면 GAN이 가장 유명하니까(적어도 내 기준엔?)

그것만 알면 되겠지라고 생각했었는데, 꼭 그런 것도 아니었나 싶기도 하고.

알아두면 좋으니 정리해보려고 하는데 정리가 마음에 들지 않고 내용도 (심지어 스스로에게도) 불확실해서

지금 **수정 중** 에 있어 일단 올리지 않고 있다.

예시 같은 것들이 조금 풍부하고 명확했으면 좋겠다 싶어서 그런 것도 있다.

물론 그런 예시는 Notion에나 올리겠지만 이렇게 좀 정리해둬야 Notion에도 올리기 편하다.

(살짝 Notion에 정리하기 전에 Structure를 가다듬는 행위라고 보면 된다.)

따라서 내일 계획은 월요일/수요일/목요일 정리에 미진했던 부분을 다시 점검하는 식으로 계획을 잡았다.

</div>
</details>

<details>
<summary>강의 내용(It will be uploaded later)</summary>
<div markdown="1">

Generative Model

강의의 처음 부분에서 소개되는 리처드 파인만의 판서(?)에 쓰인 내용이다.
> What I can not create (is) I do not understand.
>> 무슨 뜻일까 고민을 했는데, 저 괄호를 집어넣으면 말이 되긴 하네
>>
>> 내가 이해하지 못한 것을 만들 수가 없다.
>>
>> 왜 소개하셨을까? => Genertive Model이 무엇을 이해하는 지를 알았으면해서 였을까?

Generative Model에 대한 내용은 굉장히 그 범주가 크다는 것이 있다. 하지만 공통적으로 무엇인가를 이해하려고 한다.
> 그 무엇은 바로 Probability Distribution, data x의 확률 분포 p(x)를 찾아내려고 하는 것이다.

Generative Model의 범위에 대해서, 강의는 아래와 같이 소개하고 있다.

1. Generation
   > 학습한 확률 분포로부터 새로운 데이터 x_new를 샘플링하는 것
   >> 이런 행동이 가능한 모델을 Implicit Model이라고 함.
2. Density Estimation
   > 확률 분포 p(x)를 바탕으로 어떤 데이터 x의 명시적인 확률을 제시하는 모델 (Discriminative Model, Anomaly Detection 등이 해당)
   >> Generation과 함께 이런 행동이 가능한 모델을 Explicit Model이라고 함.
   >>
   >> Discriminative Model도 크게 보면 Generative Model이 되는 것임.
3. Unsupervised Representation Learning
   > label이 없어도 어떤 데이터 x가 공통으로 가지고 있는 것들을 학습하는 것. (Feature Learning)
   >> 논란의 여지가 있다고 생각하시는 듯 하지만, 나는 개인적으로는 Feature Learning 역시 Generative Model이라고 생각함.
   >>
   >> GAN based로 어떤 데이터의 implict/explicit한 feature들을 추출하여 Object Re-Identification을 하는 연구들이 진행되고 있고,
   >>
   >> 생각보다 그와 관련된 연구에서 성능이 좋다. 다양한 방법론과 활용에 따라서 Generative Model에 포함될 수 있다고 생각한다.
   >>> 즉, 여기서 뽑는 Feature들이 그 Object를 Representation할 수 있다고 보는 것이다.

기본적인 이산 확률 분포 모델을 설명해주셨는데, 아래의 두 모델을 설명해주셨다.

1. Bernoulli Distribution : 베르누이 분포, 동전 던지기 모델

2. Categorical Distribution : 카테고리 분포, 주사위 던지기 모델

동전/주사위 던지기 모델을 나타내는 두 분포가 왜 중요했을까?

이는 이미지에서의 Generative Model을 설명하기 위한 Build Up이라고 생각한다.

각 픽셀은 1번의 시행을 나타낸다고 가정했을 때,

이진 영상(Binary Image)은 그 영상을 Bernoulli Distribution으로 모델링 가능하며

일반적인 영상은 Categorical Distribution으로 모델링 가능하다.

픽셀 1개가 가질 수 있는 가중치의 수를 계산하면 아래와 같다.

> 1. Binary Image : 1
> 2. 8-bit Grayscale Image : 255
>> 255 = 2^8 - 1
> 3. 16-bit Grayscale Image : 65,535
>> 65535 = 2^16 - 1
> 4. 8-bit Color Image : 16,777,215
>> 16777215 = (2^8) * (2^8) * (2^8) - 1 = 2^24 - 1
> 5. 16-bit Color Image : 281,474,976,710,655
>> 281474976710655 = (2^16) * (2^16) * (2^16) - 1 = 2^48 - 1

위 계산은 경우의 수에서 1개를 빼면(가중치의 합은 1이 되어야 하니까) 나온다.

와! 상상이 안될만큼 거대한 숫자다.

그런데 이걸로 끝이 아니다! 이제 MNIST 기준으로 28x28=784개의 픽셀이 있는 이미지에 대한 가중치의 숫자를 구하면..

(단, 각 픽셀은 서로 독립적이라고 가정한다.)

> 1. Binary Image : (1+1)^784 - 1
> 2. 8-bit Grayscale Image : (255+1)^784 - 1
> 3. 16-bit Grayscale Image : (65,535+1)^784 - 1
> 4. 8-bit Color Image : (16,777,215+1)^784 - 1
> 5. 16-bit Color Image : (281,474,976,710,655+1)^784 - 1

어... 이건 좀.. 저렇게 많은 가중치를 게산하란 말인가!!!

그렇기에 우리는 각 픽셀은 어느정도 의존적이라고 가정하여 모델링을 조금 하면 괜찮긴 하다.

이렇게 모델링 한 것을 Autoregressive Model이라고 부른다.

어... 저 단어 어디서 많이 봤다. 무려 어제한 RNN 모델이다.

이제부터는 Notion에 나머지를 정리해두겠다. 관심 있으면 와서 보면 된다.

</div>
</details>

<details>
<summary>후일담 및 차기 계획</summary>
<div markdown="1">

*또!*  또!!  **또!!!** 생활패턴이 망가졌다.

어제 2시간 밖에 안자서 오늘 11시간 잤다.

이렇게 해서는 안되는데... 어제 정리도 사실 제대로 못했고, 기껏 한 정리는 그닥 맘에 들지 않는다.

뭐 좋은 거라면 강의는 그래도 들어서 복습한다는 셈치면 되는 것이긴 하니까.

그리고 불행인지 다행인지 이번주 논문 공부는 Transformer니까

조금 더 심기일전해서 정리할 필요가 있다고 본다.

그리고 사실 강의 분류가 DL Basic인거부터 이거 제대로 안잡고 넘어가면 안 될 것 같기도 하고. ㅋㅋ

아무튼 한 줄 요약은
>**나 죽갔슈요.**

</div>
</details>

