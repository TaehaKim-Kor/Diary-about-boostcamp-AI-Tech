<details>
<summary>Writing Specification</summary>
<div markdown="1">

>Date : 22.01.25
>
>강좌 분류 : Pytorch
>
>>강좌 번호 : 4
>>
>>제목 : AutoGrad & Optimizer
>
>>강좌 번호 : 5
>>
>>제목 : Dataset & Dataloader

</div>
</details>

<details>
<summary>오늘 들은 강의 총평</summary>
<div markdown="1">

강의가 전반적으로 실질적인 코딩에 관련되다보니 정리할 내용은 많지는 않다만,

중요도는 전혀 줄어들지 않아서 학습의 정리적인 측면에선 아쉬운 상황이다.

오늘 배운 내용 자동미분/최적화/데이터셋/데이터로더는 신경망을 구성함에 있어 중요한 내용이지만

Pytorch가 자동적으로 해주는 부분이 많아서, 그 요소별로 이해해야 도움이 되긴 한다.

사실, 자동적으로 해주니까 Pytorch를 쓰는 것이기도 하다.

</div>
</details>

<details>
<summary>강의 내용</summary>
<div markdown="1">

<details>
<summary>AutoGrad & Optimizer</summary>
<div markdown="1">

가장 작은 단위를 만들고, 그 단위를 재사용하여 또 다른 단위를 만들고, 이를 반복하는

OOP는 굉장히 많은 코드들이 활용하고 있다.

신경망의 깊이가 길어질수록 OOP의 활용은 더 중요할 것이다. ResNet뒤의 숫자가 신경망의 깊이 아니던가?...

Pytorch가 연구용으로 자주 쓰이는 이유는, 자동 미분 대신에 유저가 정의한 미분을 쓸 수도 있고,

동적 그래프 할당 방식으로 코딩도 자유로운 편이라 새로운 구조를 제안하기에 편해서 그런 것 같다.

</div>
</details>

<details>
<summary>Dataset & Dataloader</summary>
<div markdown="1">

그런 의미에서 Dataset 클래스를 만들고, dataloader를 만드는 강의는 조금 더 자세했으면 어땠을까 싶기도 하다.

데이터셋의 전처리 과정이 생각보다 많고 심오한 편이라, 코딩 기초만 다루는 Pytorch 강의에서 안 다룬 느낌인데

결국 이건 또 강의 외적으로 혼자 고민해야하는 문제인가..

일단 그래도 내용을 정리하면

Custom Dataset을 만들 때, 핵심은 Dataset 클래스를 상속받고

__init__이랑 __len__과 __getitem__을 선언해줘야한다.

__init__은 초기 클래스 내 변수들을 지정하고

__len__은 전체 데이터의 길이를 반환하고

__getitem__은 보통 index 값을 주었을때 그 index에 있는 데이터를 반환하는 함수를 구현한다.

모든 데이터 전처리를 데이터 생성 시점에 처리할 필요는 없다지만, 그렇게 안 해두면 보통 보기가 어렵던데..

유연한 사고가 필요하다지만, 어디에서 더 해야할 일이 있을지 궁금하긴 하다.

RGB 이미지 normalize를 할 때, Computer Vision 연구에서 대부분 쓰이는 RGB 평균값은 ImageNet으로 기억하는데

어떤 데이터셋의 평균값을 사용하는 것이 (관습적으로)굳어진 것으로 알고 있다.

(또는 Pretrained 모델을 쓰니까 그런 것일 수도 있고)

이 부분이 데이터 셋에 대한 표준화된 처리방법 제공이란 내용이지 않을까 싶다.

</div>
</details>


</div>
</details>

<details>
<summary>후일담 및 차기 계획</summary>
<div markdown="1">

gather... hook.... apply..... 요 3개빼고 과제는 얼추 한 거 같고.,.

부덕이... 부앵이.....

왜 이름을 이렇게 지었을까.... 전자는 이름이 부정적인 느낌이고 오른쪽은 부엉이 같음..

별개로 이런 코딩 강의에 대해서 학습 정리를 깔끔하게 할 수 있는 방법은 뭐가 있을까?

차기 계획

1. 6~7강 강의 듣고 과제 풀기

2. 기본과제 마무리 짓기

</div>
</details>
