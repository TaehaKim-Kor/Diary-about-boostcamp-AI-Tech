<details>
<summary>Writing Specification</summary>
<div markdown="1">

>Date : 22.01.20
>
>강좌 분류 : boostcamp AI Tech - AI Mathmatics
>
>>강좌 번호 : 9
>>
>>제목 : CNN 첫걸음
>
>>강좌 번호 : 10
>>
>>제목 : RNN 첫걸음
>
>강좌 분류 : boostcamp AI Tech - Python
>
>>강좌 번호 : 5-1
>>
>>제목 : File / Exception / Log Handling
>
>>강좌 번호 : 5-2
>>
>>제목 : Python Data Handling
>
>>강좌 번호 : 6
>>
>>제목 : Numpy

</div>
</details>

<details>
<summary>오늘 들은 강의 총평</summary>
<div markdown="1">

RNN과 CNN은 많이 이해했던 것으로 생각하고 있었다.
강의 듣기 전에 퀴즈를 풀었을 때도 크게 문제 없이 풀었던 거라서 괜찮겠거니 했는데

심화 과제에서 RNN의 역전파를 구하는 곳에서 크게 애먹었다.

사실 영상 처리에서 RNN을 접하는 것은 쉽지 않다.

근본적으로는 영상(Image)이 시계열 데이터가 아니기 때문이지만(하지만 분명 관련 연구가 많을 것이다),

내 연구 주제는 조금 더 고전적인 영상 처리 공학의 문제를 신경망을 활용한 해결 쪽에 가까웠기 때문에 별로 관심이 없었다.(ConvLSTM정도만 기억나네..)

(대학원 입학하고 처음으로 영상 처리를 공부하면서 별도로 RNN을 공부해보긴 했는데, 그 땐 모든 게 처음인지라.. 생각해보면 역전파를 그 때도 구해본 것 같기도 한데 자료를 못 찾고 있다.)

시계열 데이터 쪽도 최근엔 Transformer와 같은 Attention 모델이 RNN 계열 모델을 다 압도했다고 듣긴 했지만,

RNN은 그 구조 역시 꽤 역사 깊은 구조라고 생각해서 공부해두면 입력 신호를 필터링하는 시스템을 이해하는 측면에서 통찰을 얻을 것이라고 생각한다.

CNN은 컴퓨터 비전에서는 너무 중요한데,

기존의 Perceptron에서 얻을 수 없었던 공간에 대한 정보(Spatial Information)를 신경망이 이해한다는 관점에서 너무 중요하다.

흔히 CNN은 입/출력 텐서의 차원을 맞추는 것에 집중하고, 딥 러닝 강의들이 대부분 이 파트를 시험으로 낸다고 하면 그런 문제를 내는 편이긴 하다.

차원 계산 문제도 물론 중요하다(선대수 관점이라던지, 코딩 관점이라던지 practical하게 중요하다.)

하지만 난 관점이 이 것에 비하면 조금 다른데(여기엔 아마 내 지도 교수님 영향도 있을 것이지만)

각 커널 하나하나마다 필터의 특성을 조금 더 신경써서 보는 편이다.(그렇다고 신경망 파일을 열어서 필터 하나씩 보고 있지는 않음)

그에 대한 생각을 여기다가 적고 종합해보는 시간을 써보도록 하겠다.

</div>
</details>

<details>
<summary>강의 정리</summary>
<div markdown="1">

오늘 강의는 많이 들은 것이 없어서 CNN, RNN 두 분야로 나누어 보면 되겠다.

(22.01.21) -> 다만 내가 오늘 조금 쉰 관계로, RNN은 확률/통계론과 더불어 주말에 작성하도록 하겠다.

<details>
<summary>CNN</summary>
<div markdown="1">

나는 CNN을 이야기하기 전에, 영상 처리 공학의 전반적인 흐름에 대해 이야기 해보고 싶다.

영상 처리 공학의 시작은 무엇일까?

기본적으로 영상 처리 공학의 시작은, 카메라 센서로부터 정보를 어떻게 처리할 것인가?로 시작한다.

그렇기에 모든 영상 처리 공학 과목이 아마 데이터를 이해하는 것에서 시작할 것으로 생각한다.

디지털 공학 내 영상 처리 공학에서 영상은 카메라 센서로부터 측정 값을 받아 약속한 값의 범위 내에서 측정 값을 정렬한 다음, 양자화(Quantization)하여 저장된다.

크게 접하는 데이터로는, 0~255 범위 내 정수의 형태로 저장된 이미지와 0~1 범위 내 실수의 형태로 저장된 이미지가 있다.

쉽게, 값의 범위는 다를 수 있다만, 크게 보면 정수형(Integer)과 실수형(Double)으로 나눌 수 있다.

> 이를테면 나는 16비트 부호가 없는 정수형(uint16)으로 저장된 이미지를 다뤄본 적이 있다. 값의 범위만 다를 뿐이지 똑같다.
> 
> 값의 범위가 다르면, 표현할 수 있는 색상이 많아진다. 다만, 표현할 수 있는 색상의 최대/최소 값이 바뀌진 않는다.
> 
> Limitation이 아니라 Resolution(여기선 해상도가 아니라 분해능)이 좋아지는 것으로 이해하면 좋다.

그러면 데이터를 저장도 했겠다, 다음 영상 처리 공학의 목표가 무엇이었을까?

그것은 바로 영상 내 관심이 있는 영역만 추출하는 것이다.

어떤 입력으로부터 원하는 출력을 반환하는 시스템을 우리는 주로 필터(Filter)라고 부른다.

> 교재에 나온 커널(Kernel)은 필터라고도 부르며 가끔 윈도우(Window)라고도 부른다.

[필터](https://en.wikipedia.org/wiki/Filter)는 정말.. 너무 많은 의미가 있다. 내가 관심이 있는 필터는 [이쪽](https://en.wikipedia.org/wiki/Filter_(signal_processing))이다.

갑자기 신호 처리로 넘어가니 조금 이상할 수도 있다.

하지만 나는 모든 공학은 목표가 다르고 말은 달라도 궤를 같이 한다고 보는 편이다.

왜냐하면 밑바탕은 수학이기 때문이다. 수학을 현실로 비유하면 공학은 현실을 표현하는 언어라고 생각한다.

신호 및 시스템이나 신호 처리 과목에서 필터라는 시스템은 전달 함수라는 개념을 통해 해석한다.

> 필터 : 시간 도메인 t에서 입력 신호 x(t)를 출력 신호 y(t)로 변환해주는 함수
> 
> 필터의 전달 함수 : 시간 도메인 t를 라플라스 도메인 s, (각)주파수 도메인 $\omega$ 로 변환 했을때 다음의 수식이 만족함. 이는 연속 시간에서의 정의이고, 이산 시간에서는 z-transform을 통해 z 도메인으로 정의한다.
> 
> $$Y(s) = H(s)X(s)

신호 처리 과목을 배우면서 이 전달 함수는 거의 1+1마냥 듣게되는데, 이 전달함수의 특성을 특성 방정식(Characteristic Equation)이나 주파수 응답(Frequency Response)을 통해 해석하여 High Pass Filter, Low Pass Filter, Band Pass Filter, Band Stop Filter 등으로 나눈다.

교재 9페이지에 나온 사이트에 있는 다양한 필터들이 저 위에 언급된 필터의 성향을 하나를 가지고 있다고 보면 된다.

이제 CNN으로 돌아가,

[Convolution](https://en.wikipedia.org/wiki/Convolution)은 무엇일까?

위의 링크, 위키피디아의 정의에 의하면,

> 두 함수로부터 하나의 함수가 다른 함수에 의해 어떻게 바뀔것인지를 나타내는 새로운 함수를 생성하는 수학적인 연산

으로, 두 함수 중 하나를 축에 반전시키고 움직여가면서 겹치는 부분을 곱한 함수를 적분하는 함수이다.

[Cross-correlation](https://en.wikipedia.org/wiki/Cross-correlation)은

한 함수를 축에 반전시키지 않고 움직여가며 겹치는 부분을 곱한 함수를 적분하는 것이다.

반전의 유무만 차이가 있는 것인데, 연산은 Cross-correlation으로 하지만 이름이 Convolution인 이유는

교수님의 설명대로 관습의 차이기도 하지만, 사실 Convolution에는 중요한 특성이 있기 때문이다.

> Convolution은 Dirac Delta Function(Impulse Function)과 연산하면 필터의 특성을 그대로 출력해 보여준다.
>
> 반대로 Cross-correlation은 Dirac Delta Function과 연산하면 필터의 특성이 역전되어 출력된다.

신호 처리 과목이나 제어 공학이나 이 연산을 이용해 시스템을 해석하는 이유이기도 하다.

궁금하면, 이걸 연산해보면 된다. 출력되는 kernel의 순서를 비교하며 잘 보도록 한다.

> import numpy as np
>
> from scipy import signal
>
> kernel = np.array([[1,2,3],[4,5,6],[7,8,9]])
> 
> impulse = np.array([[0,0,0],[0,1,0],[0,0,0]])
> 
> print(signal.convolve2d(impulse,kernel,mode='same'))
> 
> print(signal.correlate2d(impulse,kernel,mode='same'))

그러나 연산의 차이가 크게 나지 않아서, Cross-correlation으로 계산하는 것인데,

그 결과 현재 신경망이 생성해낸 각 커널들은 사실 역전된 필터로 보는 것이 맞다.

그 외에 강의에서 중요한 것은 차원이 어떻게 출력되는 것인가인데, Padding, Stride를 고려하지 않아 조금 수식이 간단해 보이는 것 같다.

입력되는 텐서의 한 차원의 길이를 W1

출력되는 텐서의 같은 차원의 길이를 W2

필터의 같은 차원의 길이를 F

Stride(커널 연산 후 몇 픽셀 움직일 것인가)를 S

Padding size(입력되는 텐서의 테두리를 늘려 커널 연산을 모서리에서도 할 수 있게끔)를 P

로 하면 다음의 수식이 성립된다.

> W2 = (W1 - F + 2P) / S + 1 

</div>
</details>

<details>
<summary>RNN 정리중</summary>
<div markdown="1">

여기다 적어

</div>
</details>

</div>
</details>

<details>
<summary>후일담 및 차기 계획</summary>
<div markdown="1">

... 사실 오늘 좀 많이 잤다. 어제 무리한 반동 탓인지.

10시 30분에 잔 것으로 기억하고, 6시에 일어났다.

주말도 있으니까, 싶었는데 이번 주 주말은 은근 바쁘더라.

차기 계획
1. 파이썬 남은 강의 듣기
2. 확률론, 통계론, RNN 정리

</div>
</details>