<details>
<summary>Writing Specification</summary>
<div markdown="1">

>Date : 22.02.08
>
>강좌 분류 : DL Basic
>
>>강좌 번호 : 3
>>
>>제목 : Optimization
>
>>강좌 번호 : 4
>>
>>제목 : Convolution
>
>>강좌 번호 : 5
>>
>>제목 : Modern CNN
>
>>강좌 번호 : 6
>>
>>제목 : Computer Vision Application

</div>
</details>

<details>
<summary>오늘 들은 강의 총평</summary>
<div markdown="1">

오늘 강의는 Deep Learning, 특히 CNN에서 다룬 내용들이 많았다.

Computer Vision은 적어도 2차원 데이터를 쓰다보니 CNN을 쓰지 않을 수가 없는데,

그런 점에서 굉장히 의미 있는 강의였다고 생각한다.

또 실제 내게 필요한 실습강의가 포함되어 있어서 능동적으로 들을 수 있었다.

</div>
</details>

<details>
<summary>강의 내용</summary>
<div markdown="1">

<details>
<summary>Optimization</summary>
<div markdown="1">

최적화를 달성하기 위해서, 정말 많은 기술들이 사용된다.

1. Gradient를 계산할 때 한 번에 사용할 데이터의 양을 결정하는 Batch size를 기준으로

Stochastic/Mini-batch/Batch Gradient Decent로 나누며, mini-batch를 사용할 때 Generalization 성능이 증가한다.

2. Optimizer는 Gradient의 학습양을 결정하는 기술로 아래와 같은 것들이 있다.
   
> SGD
> 
> Momentum
> 
> Nesterov Accelerated Gradient
> 
> Adagrad
> 
> Adadelta
> 
> RMSProp
> 
> Adam

위와 같은 Optimizer의 핵심은 Local Minima에서 벗어나 Global Minima로 빠르게 수렴을 할 수 있도록 하는 것이다.

특히 실습 강의에서 학습할 때 데이터의 영향력 관점에서 SGD와 Momentum을 비교하는 것도 인상깊었다.

사실 대학원에서 배울 때는 이런게 있구나만 했었는데, 진짜 이런 통찰력이 필요하다.

뭐 이렇게 주저리 주저리 적어놔도 결국 Adam 쓸테지만.

3. Regularization
   
Regularization은 학습데이터뿐만 아니라 테스트 데이터에도 신경망이 잘 동작하도록 만드는 기술을 의미한다.

그리고 그것을 이루기 위해서 학습을 어렵게 만들거나 아예 과정을 망쳐 놓는 것이라고 보면 된다.

> Early stopping : Validation Set에서 성능이 오르지 않으면 학습을 중단시키는 기술.
> 
> Parameter Norm Penalty(Ridge,Lasso 회귀) : 파라마티의 절대값이 크지 않게 손실함수에 패널티를 줌.
> 
> Data Augmentation : 데이터를 변형시켜 제한된 데이터셋을 증강시키는 기술
> 
> Noise Robustness : 데이터와 가중치 Noise를 부여하는 기술
> 
> Label Smoothing : 두개 이상의 서로 다른 라벨의 데이터를 섞어서 학습시키는 기술
> 
> 경계선 부근의 데이터를 보는 효과가 있음. Mixup/Cutout/Cutmix 등이 있음.
> 
> Dropout : 신경망 내 일부 노드를 무력화시키면서 학습시키는 기술, 테스트에는 옵션을 꺼야함.
> 
> Batch Normalization : 정규분포에 가깝게 layer의 statistics를 조정하는 기술

</div>
</details>

<details>
<summary>Convolution</summary>
<div markdown="1">

Convolution에 대한 이야기는 이전에 열심히 정리했으므로 패스~

결국 Contolutional Neural Network의 목표는 어떤 Feature의 군집, Feature Map을 추출하는 것이 목표

**Classical한 CNN 계열은 이 Feature Map을 FCN에 통과시켜 Decision Boundary를 계산하는 것이 목표였음.**

1x1 Convolution은 다음 장에서 더 중요하게 다루는 내용이니 패스

</div>
</details>

<details>
<summary>Modern CNN</summary>
<div markdown="1">

이 강의에서는 흔히 SOTA라고 불린 모델들을 가져와 설명한 강의이다.

CNN의 개발 추세는 아래와 같다.

1. layer는 더 깊게

2. parameter는 더 적게

3. performance는 더 좋게

어떻게 이 3개를 달성했는지를 보면 될 듯.

AlexNet의 특징
1. Rectified Linear Unit, ReLU의 사용
2. 다중 GPU로 구현
3. Local Response Normalization, LRN의 사용 -> 이젠 안 씀.
4. Overlapping Pooling의 사용(기존의 Pooling 2x2형태로 겹치지 않게 했었음.)
5. Data Augmentation의 사용
6. Dropout의 사용

VGGNet의 특징
1. 모든 Convolution Filter의 Kernel Size를 3으로 통일(3x3, stride=1)
2. Dropout의 사용
3. Fully Connected Layer를 위해서 1x1 Convolution을 사용

>3x3 Convolution Filter를 사용하는 이유
>> 같은 Receptive Field에서 더 적은 Parameter를 사용할 수 있음.
>> Receptive Field : 필터가 보는 영역의 크기
>>> example : 5x5 = 3x3의 2번 적용

GoogLeNet의 가장 큰 특징
>여러 Receptive Field와 연산을 가진 Convolution Layer 전/후에
>
>**1x1 Convolution Filter**를 적용한 Inception Block
>> 1x1 Convolution Filter를 사용하면 Channelwise Dimension Reduction을 더 적은 parameter로 가능

ResNet의 가장 큰 특징

1. Skip Connection을 통한 Degradation Problem을 해소
> Skip Connection : Block의 출력에 입력을 더해주어 Block이 입력의 잔차를 학습하도록 함.

2. Bottlenect Architecture의 적용
> GoogLeNet의 Inception Block과 유사함. 3x3 Convolution하기전에 1x1 Convolution을 함.

DenseNet의 가장 큰 특징
> Skip Connection을 더해주지말고 Concatenate를 해줌.
>> 결합을 해주면 신경망이 깊어질수록 채널이 커지고, 이에 따라 가중치 숫자가 커지는 문제가 발생
>>> Transition Block으로 feature의 size(avgpool)와 channel(1x1 convolution)을 감소

</div>
</details>

<details>
<summary>Computer Vision Application</summary>
<div markdown="1">

Semantic Segmentation : 영상 내 각 픽셀이 무슨 객체인지 찾는 문제
> Fully Connected Layer로는 도달할 수 없음.
>> Fully Convolutional Network의 도입(Conolutionalization)
>>> 해상도에 무관하게 신경망이 동작함(그냥 필터의 집합이 되어버림) heatmap 등 다양한 활용 가능

보통 Fully Convolutional Network는 입력보다 출력의 크기가 작아서 Subsampling을 해야함.
> Deconvolution의 개발
>> 원리는 Convolution과 똑같은데 결과가 반전(더 커짐)

Object Detection : 영상 내 객체가 어디있는지 Bounding Box로 표시(Localization)

R-CNN : ~~윽 PTSD가...~~

1. Selective Search로 영상 내 Bounding box를 2천개 가까이 결정
   
2. AlexNet을 Backbone으로 활용하여 각 Bounding box의 Feature map 추출
   
3. SVM으로 판별
> 이걸 다 연산하면 이미지 하나당 2천개의 신경망 연산이 필요

SPPNet 

1. 이미지 전체에 대한 Feature Map을 만든다.
   
2. Spatial Pyramid Pooling을 통해 Region별로 Feature Map을 가져와 객체를 판별
> 이렇게 하여 CNN은 단 한번만 사용하도록 바꿈

Fast R-CNN
1. Selective Search로 영상 내 Bounding box를 2천개 가까이 결정
   
2. Convolution Feature Map을 추출
   
3. ROI pooling layer로 고정된 길이를 가진 feature vector를 추출
   
4. 객체가 무엇인지 판별하는 softmax layer와 bbox를 추론하는 bbox regressor로 객체 탐지

Faster R-CNN

(Fast)R-CNN 에서 기존에 사용하던 Selective Search를 대체하는 새로운 신경망

**Region Proposal Network(RPN)**을 제안하였음.
> 이쪽 분야에서 위상만 보면 거의 업계 표준급임.
>>미리 결정된 Detection Box인 Anchor Box를 이미지 패치별로 찾아다니면서 객체가 있을 것 같은 bbox를 탐색

YOLO

앞에서 다룬 논문들을 보통 2-stage Detector라고 부르는데, YOLO는 1-stage Detector임.
> (Multi/Single이라고도 함)

Selective Search/RPN등의 과정 없이, 미리 이미지의 Grid를 나누고

**Grid의 Class를 추론함과 동시에 Grid의 Boundingbox를 동시에 추론함.**

</div>
</details>

</div>
</details>

<details>
<summary>후일담 및 차기 계획</summary>
<div markdown="1">

확실히 논문 리뷰, 구현을 스스로 해보자고 한 것들이 오늘 강의를 이해하는데 도움이 많이 되었다.

다음 논문은 일단 Attention is all you need라는, Transformer라는 구조에 대한 것을 리뷰해보기로 했는데,

다음 강의가 Transformer인 만큼 열심히 들어야겠다.

모델들을 구현하는 연습을 해보면서 점점 코딩같은 것도 늘 것이라고 생각한다.

뭔가 많이 깨달아가는 시기(?)라고 생각되는 요즘이다.

차기 계획

1. 강의 7~10강까지 듣기
   
2. ViT하기(어제 AAE했음.)

</div>
</details>
