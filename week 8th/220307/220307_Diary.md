<details>
<summary>Writing Specification</summary>
<div markdown="1">

>Date : 22.03.07
>
>강좌 분류 : Computer Vision
>
>>강좌 번호 : 0
>>
>>제목 : Computer Vision Overview
>
>>강좌 번호 : 1
>>
>>제목 : Image Classification 1
>
>>강좌 번호 : 2
>>
>>제목 : Annotation Data Efficient Learning
>
>>강좌 번호 : 3
>>
>>제목 : Image Classification 2

</div>
</details>

<details>
<summary>오늘 들은 강의 총평</summary>
<div markdown="1">

4주차 강의의 완전 복습이었다.

사실 나는 이걸 어떻게 정리해야할지 조금 고민이 되었다.

그래서 알게 된 것이나 나름 중요하다고 생각하는 것들을 문장 단위로 정리해보았다.

</div>
</details>

<details>
<summary>강의 내용</summary>
<div markdown="1">

<details>
<summary>Image Classification 1</summary>
<div markdown="1">

1. Computer Vision과 Computer Graphics가 서로 반대되는 개념인 것을 처음 알았다.

2. Thatcher Illusion과 같은, 사람의 눈을 속이는 것들은 많이 존재한다. 인간의 시각도 불완전하다.

3. 기존의 기계 학습(SVM, K-means clustering)은 사람들이 직접 알고리즘을 설계한 필터(SIFT, SURF 등)를 이용한 Feature들로 학습했다.

4. 이를 Deep Learning이 발전된 지금에서는 Feautre Extraction도 학습하도록 한 것이다.

5. Classification 문제는 모든 데이터를 다 확보하고 있다는 가정 하에선 k Nearest Neighbor 문제로 바뀐다. 이 알고리즘은 강력하지만, 추론에 너무 오랜 시간이 걸리고, 메모리를 너무 많이 사용하며, 영상간의 유사도를 정확히 정의할 방법이 없다는 문제점을 가지고 있다.

6. 일단 전제 조건인 방대한 양의 데이터를 모두 확보할 수 없으니, Neural Network로 압축된 정보를 녹여 넣고 제한된 복잡도 내에서 이를 수행하도록 만든 것이다.

7. Fully connected layer로 이미지를 학습했을 때, 그 가중치를 이미지의 형태로 만들면 각 클래스별 평균 영상과 비슷한 형태가 된다. 물론, crop한 이미지 등을 제대로 추론할 수 없게 된다.

8. 그 점을 해결하기 위해 만든 것이 CNN으로, (정확히는 Correlation이지만)Convoultion 연산을 하는 수많은 필터들을 moving window로 해석해 나간다. 가중치를 공유하기 때문에 상대적으로 적은 가중치로도 더 나은 모델을 구현할 수 있다.

9. AlexNet은 ReLU와 Dropout, 지금은 Batch Normalization으로 쓰는 Local Response Normalization을 사용한 케이스이며, ImageNet으로 학습되었다.

10. VGGNet은 LRN을 쓰지 않고, 오로지 3x3 Convolution filter와 2x2 maxpooling으로 더 간단한 구조에 더 좋은 성능을 낸 신경망이다.
    
</div>
</details>
<details>

<summary>Annotation Data Efficient Learning</summary>
<div markdown="1">

1. Data Augmentation은 부족한 데이터셋을 증강하는 방법론을 지칭한다. 이는 우리가 Real world의 분포를 따르는 데이터셋을 확보하는 것이 제일 좋겠지만, 이는 거의 불가능하기 때문에 보조하는 방법으로 채택하는 것이다.

2. Augmentation엔 밝기변화, 색조변화, 회전, 자르기, 뒤집기, 아핀 변환(Affine Transformation), Cutmix, Mixup 등이 있다. Cutmix와 Mixup등을 쓸 때는 Label도 섞어야 한다.

3. RandAugment는 이를 자동으로 해준다. 즉 Augmentation Policy를 자동으로 결정해주는 것인데, 여기서는 grid search를 사용했다고 한다만 논문을 내가 읽진 않았다. 만약 NAS와 비슷한 개념으로 구현한다면 이것도 아마 강화학습 이론 기반으로 구현할 수도 있을 것이다.

4. 천이 학습(Transfer Learning)은 기존에 학습된 신경망(Pre-trained Networks)을 이용하여 현재 내가 가지고 있는 적은 데이터셋으로도 학습을 가능하게 만드는 실용적인 방안에 대한 것이다. 보통은 ImageNet과 같은 거대한 데이터셋으로 학습한 신경망을 보다 작은 데이터셋에 학습시키는 것으로 진행한다.

5. Transfer Learning에서 ImageNet과 비교했을 때 다른 task를 맡는 신경망을 학습시킨다면 Backbone은 freeze하고 뒷단의 FCN을 학습시키는 방법과 Backbone은 상대적으로 작은 learning rate로, FCN은 높은 learning rate로 학습시키는 방법이 있다.(사실 나는 Dataset의 종류 등과 가지고 있는 데이터 등을 전부 보고 결정해야 한다는 마인드이긴 하다.)

6. Knowledge Distillation(Feature Distillation)은 미리 학습된 신경망으로부터 같은 출력을 내도록 더 작은 신경망을 학습시키는 방법을 의미한다.(다른 말로 Teacher-student model이라고 한다.) student model에 따로 들어가는 Cross Entropy Loss등을 Student loss라고 하며, Teacher model과 student model의 출력을 KL-Divergence loss 등으로 최적화하는 것을 Distillation loss라고 할 때 이를 가중합으로 최종 목적함수로 결장한다.

7. Semi-supervised learning은 불완전한 데이터셋을 학습하기 위해 미리 학습된 신경망으로부터 Pseudo-labeling을 해서 불완전한 데이터셋을 보다 더 완전한 데이터셋으로 만들어서 큰 신경망을 학습시키는 과정을 신경망을 바꿔가면서 반복하는 것을 의미한다.

8. 위에서 언급한 Randaugment, Teacher-student, Semi-supervised learning을 모두 합친 것이 self-training이다.

9. 강의자료에는 있는데 언급되지 않은 Learning without Forgetting도 했으면 어떨까 싶다. 이것도 요즘 뜨겁던뎅...

</div>
</details>
<details>

<summary>Image Classification 2</summary>
<div markdown="1">

1. 한 때 신경망 연구는 깊게 쌓는 것에 몰두한 경향이 있었는데 VGG 같은 깊은 신경망이 만들어진 이후에 신경망을 깊게 쌓으려니 Gradient Vanishing/Exploding과 같은 문제들이 발생했다.(사실 Computational complex의 증가는 어쩔 수 없는 것 아닌가?... 어느정도는 노리고 깊게 쌓는 것으로 알고 있었는데...) 기존의 연구자들은 이 과정에서 test 성능이 증가하지 않고 포화되는 overfitting 문제를 겪는다고 생각했다.

2. 그런데 ResNet연구자들은 더 깊은 모델이 train과 test 성능 모두 좋지 않다는 것에 기인하여 overfitting이라는 문제 말고 degradation problem을 새로 정의했다. degradation problem은 더 깊은 신경망이 얕은 신경망과 비교했을 때 학습을 못하는, 최적화 달성을 실패하는 경향을 지칭한다. overfitting은 train은 잘 하는데 test를 못하는 것으로 결이 완전히 다른 문제이다.(가끔 외부 블로그에서 이런 걸 명시하지 않는 케이스들이 있는데, 이는 분명히 논문에 나와 있는 내용이다.)

3. GoogLeNet은 Inception Module을 활용하였고, 이것은 1x1 Convolution을 이용해 같은 receptive field에 대해서 더 적은 가중치로 구현하였다. 이런 Inception moudle을 여러개 쌓았고, Auxiliary Classifier를 통해 Gradient Vanishing 문제를 해결하였다.(Auxiliary Classifier는 학습 단계에서만 신경망 모델 중간 중간에 별도의 Loss를 흘려주는 분류기를 의미한다. 추론 단계에서는 폐기된다.)

4. ResNet은 아주 간단한 Residual module의 출력에 Shortcut Connection(Identity Mapping)을 통해 입력과 직접 연결해서 Gradient Vanishing 문제를 해결하고, 입력에 대한 출력의 잔차를 학습하도록 문제를 바꾸어 학습을 더 쉽게 만들었다. 이런 간단한 구현만으로도 Residual Block은 더 다양한 신경망의 forward path를 갖게 되고(backward path도 마찬가지) 기존의 신경망이 달성하지 못했던 아주 깊은 깊이의 신경망도 도달하게 되었다.

5. DenseNet은 ResNet의 더하기를 Concatenate를 대체하여 메모리의 사용량을 늘렸지만 기존의 Feature가 더 직접적으로 전파되도록 만든 신경망이다.

6. SENet은 Attention 개념을 가져온 것으로 여기서 Attention은 global average pooling을 하는 Squeeze와 channel-wise attention weights를 FC layer에 곱해주는 Excitation이란 과정으로 구현하였다.

7. EfficientNet은 모델의 넓이(Wide), 깊이(Depth), 입력의 해상도(Resolution)을 모델의 절대적인 크기 내에서 다양하게 바꿔가며 학습하도록 만든 것이다.(표현이 조금 이상한데 실제 수식을 보면 가중치의 숫자 합이 정한 크기에서 벗어나지 않는다.) -> Notion에선 조금 자세히 다뤄보겠다.
   
8. Deformable Convolution은 기존의 Cnn에서 offsets을 활용해 입력 pixel의 위치도 결정하는 새로운 형태의 Convolution이다.

9. GoogLeNet보단 VGGNet이나 ResNet을 Backbone으로 많이 쓴다. 이유는 Auxiliary Classifier같은 것들이 복잡하게 만들기 때문이다.

</div>
</details>


</div>
</details>

<details>
<summary>후일담 및 차기 계획</summary>
<div markdown="1">

으... 요즘 눈이 너무 아플 때가 있다. 조금 일찍 자보고 하면서 컨디션 조절을 하고

너무 안 낫는다 싶으면 병원 한 번 가봐야지.

level 2의 첫 시작이다.

주말에 모여서 미리 테스트 파일럿을 정한 것은 너무 좋은 선택인 것 같았다.

논문 리뷰를 진행했는데, 어우.. 생각보다 준비가 더더더 잘 되어 있어서 놀랐다.

다음 나의 준비가 아찔해졌다 ^_^.... 허밍...

차기 계획

1. 4,5강 듣기

2. 논문 발표 준비

3. Rust 공부하기

</div>
</details>
